{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfCN7PLNNECz"
   },
   "source": [
    "# 手动实现经典NLP模型算法——LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1480,
     "status": "ok",
     "timestamp": 1759227546536,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "_r9skNvU8WoT"
   },
   "outputs": [],
   "source": [
    "from dataset.ptb import load_data\n",
    "from lstm.gated_rnnlm import GatedRnnlm\n",
    "from common.optimizer import SGD\n",
    "from common.utils import RnnlmTrainer, eval_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmIMvzrTPUiL"
   },
   "source": [
    "## Ⅰ、加载PTB语料数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1759227546799,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "4CP3R-hh0SrL",
    "outputId": "8eaf2863-63a2-423d-ef0e-575d36234a35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus size: 929589, vocabulary size: 10000'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = load_data(\"train\")\n",
    "corpus_val, _, _ = load_data('val')\n",
    "corpus_test, _, _ = load_data('test')\n",
    "corpus_size = len(corpus)\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "data_size = len(xs)\n",
    "'corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OX1l8YrcoOH"
   },
   "source": [
    "## Ⅱ、创建LSTM语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759227546802,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "VNUHwMNYbyeJ"
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 5.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1759227547873,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "aG2fVClIdB4G"
   },
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model = GatedRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRaIXCs7DvHB"
   },
   "source": [
    "## Ⅲ、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 46666,
     "status": "error",
     "timestamp": 1759227594541,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "LX6E3X_PdWG6",
    "outputId": "1289a326-5073-42f9-f376-86a291f40b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 1[s] | perplexity 9990.28\n",
      "| epoch 21 |  iter 21 / 1327 | time 47[s] | perplexity 2980.99\n",
      "| epoch 41 |  iter 41 / 1327 | time 88[s] | perplexity 1386.60\n",
      "| epoch 61 |  iter 61 / 1327 | time 128[s] | perplexity 1089.28\n",
      "| epoch 81 |  iter 81 / 1327 | time 165[s] | perplexity 997.82\n",
      "| epoch 101 |  iter 101 / 1327 | time 208[s] | perplexity 920.03\n",
      "| epoch 121 |  iter 121 / 1327 | time 252[s] | perplexity 925.47\n",
      "| epoch 141 |  iter 141 / 1327 | time 306[s] | perplexity 885.39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m best_ppl = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m   \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m   model.reset_state()\n\u001b[32m      6\u001b[39m   ppl = eval_perplexity(model, corpus_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp-demo\\common\\utils.py:142\u001b[39m, in \u001b[36mRnnlmTrainer.fit\u001b[39m\u001b[34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[39m\n\u001b[32m    139\u001b[39m batch_x, batch_t = \u001b[38;5;28mself\u001b[39m.get_batch(xs, ts, batch_size, time_size)\n\u001b[32m    141\u001b[39m loss = model.forward(batch_x, batch_t)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m params, grads = remove_duplicate(model.params, model.grads)  \u001b[38;5;66;03m# 共有された重みを1つに集約\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp-demo\\lstm\\gated_rnnlm.py:64\u001b[39m, in \u001b[36mGatedRnnlm.backward\u001b[39m\u001b[34m(self, dout)\u001b[39m\n\u001b[32m     62\u001b[39m dout = \u001b[38;5;28mself\u001b[39m.loss_layer.backward(dout)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m   dout = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dout\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp-demo\\lstm\\lstm_layers.py:118\u001b[39m, in \u001b[36mTimeLSTM.backward\u001b[39m\u001b[34m(self, dhs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(T)):\n\u001b[32m    117\u001b[39m   layer = \u001b[38;5;28mself\u001b[39m.layers[t]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m   dx, dh, dc = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m   dxs[: ,t, :] = dx\n\u001b[32m    121\u001b[39m   \u001b[38;5;66;03m# 累积参数梯度\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp-demo\\lstm\\lstm_layers.py:57\u001b[39m, in \u001b[36mLSTM.backward\u001b[39m\u001b[34m(self, dh_next, dc_next)\u001b[39m\n\u001b[32m     54\u001b[39m dA = np.hstack((df, dg, di, do))\n\u001b[32m     56\u001b[39m dWh = np.dot(h_prev.T, dA)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m dWx = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m db = dA.sum(axis=\u001b[32m0\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mself\u001b[39m.grads[\u001b[32m0\u001b[39m][...] = dWx\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "  trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "  model.reset_state()\n",
    "  ppl = eval_perplexity(model, corpus_val)\n",
    "  print('valid perplexity: ', ppl)\n",
    "\n",
    "  if best_ppl > ppl:\n",
    "    best_ppl = ppl\n",
    "    model.save_params()\n",
    "  else:\n",
    "    lr /= 4.0\n",
    "    optimizer.lr = lr\n",
    "\n",
    "  model.reset_state()\n",
    "  print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWS64Uw7UsVf"
   },
   "source": [
    "## Ⅳ、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1759227594566,
     "user": {
      "displayName": "Tfiyuen Lau",
      "userId": "00570328620769717926"
     },
     "user_tz": -480
    },
    "id": "lZ9dptXCl6j3"
   },
   "outputs": [],
   "source": [
    "model.reset_state()\n",
    "model.load_params(\"GatedRnnlm.pkl\")\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPxC5wwxP+ODdOko3LGkjN",
   "mount_file_id": "1n6wkRiWCBjLAzIrArq8mVmqGAQeDNNeK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
